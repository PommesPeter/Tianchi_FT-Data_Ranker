# global parameters
project_name: 'Data-Juicer-recipes-alpaca-cot-en'
dataset_path: '../data/raw_data/raw_data_en.jsonl'  # path to your dataset directory or file
export_path: ''
ds_cache_dir: '~/data1/huggingface/datasets'

np: 100  # number of subprocess to process your dataset
open_tracer: true
trace_num: 100

# process schedule
# a list of several process operators with their arguments
process:

  - document_deduplicator: # 104636705
      lowercase: true 
      ignore_non_character: true

  - clean_html_mapper:               # NOTE: from v7 diff
  - clean_links_mapper:                 # NOTE: from v6.2 diff
  - fix_unicode_mapper:              # NOTE: diff
  - whitespace_normalization_mapper: # NOTE: from v7 diff
  - punctuation_normalization_mapper: # NOTE: from v6.2 diff

  - alphanumeric_filter: # 104636381
      tokenization: false
      min_ratio: 0.4             # change from 0.1
  - average_line_length_filter:          # filter text with the average length of lines out of specific range.
      min_len: 10                        # the min length of filter range
      max_len: 10000  
  - character_repetition_filter: # 104630030
      rep_len: 10
      max_ratio: 0.6
  - flagged_words_filter: # 104576967
      lang: en
      tokenization: false
      max_ratio: 0.01              # change from 0.017
  - maximum_line_length_filter: # 104575811
      min_len: 20
      max_len: 20000
  - text_length_filter: # 104573711
      min_len: 30
  - perplexity_filter:                                      # filter text with perplexity score out of specific range
      lang: en                                                # compute perplexity in what language
      max_ppl: 1000                 # NOTE: diff
  - language_id_score_filter:                               # filter text in specific language with language scores larger than a specific max value
      lang: en                                                # keep text in what language
      min_score: 0.8                # NOTE: from v6.2 diff
  - words_num_filter:                                       # filter text with number of words out of specific range
      lang: en                                                # sample in which language
      tokenization: false                                     # whether to use model to tokenize documents
      min_num: 5                                             # the min number of filter range
  - error_filter:           # NOTE: diff
      errors: [
        'network error', 'Network error',
        'There was an error generating a response'
        ]
  # - stopwords_filter:                                       # filter text with stopword ratio smaller than a specific min value
  #     lang: en                                                # consider stopwords in what language
  #     tokenization: false                                     # whether to use model to tokenize documents
  #     max_ratio: 0.8                                          # the min ratio to filter text
  - token_num_filter:                                       # filter text with total token number out of specific range
      hf_tokenizer: data/models/falcon-rw-1b            # name of used Hugging Face tokenizer                                        # the min number of filter range
      max_num: 1500                                          # the max number of filter range

  - document_simhash_deduplicator:  # 72855345
      tokenization: space
      window_size: 3
      lowercase: true
      ignore_pattern: '\p{P}'
      num_blocks: 9
      hamming_distance: 7

  - text_len_selector:          # NOTE: from v7 diff
      text_key: "text"
      field_keys: "__dj__stats__.text_len"
      min_range: 0
      max_range: 20000
      interval: 1000
      num_sample: 80000
