# global parameters
project_name: 'Data-Juicer-recipes-alpaca-cot-en'
dataset_path: '../data/raw_data/raw_data_en.jsonl'  # path to your dataset directory or file
export_path: ''
ds_cache_dir: '~/data1/huggingface/datasets'

np: 100  # number of subprocess to process your dataset
open_tracer: true
trace_num: 100

# process schedule
# a list of several process operators with their arguments
process:

  - document_deduplicator: # 104636705
      lowercase: true 
      ignore_non_character: true

  - clean_links_mapper:
  - fix_unicode_mapper:
  - keyword_mapper:
      keywords: ['지금 번역하기', 
      '화창한 봄날 공원에서 커피먹고 있는 사자', 
      '좀 더 유니크한 키워드로 다시 찾아줘',
      'この文章をの文を一つずつ抽出し,その内容の信憑性を10段階評価にし,テーブル形式で出力してください',
      'この文章をCEFR B1相当の750～800単語の文章に書き換えてください']
  - remove_specific_languages_mapper:
      text_key: 'text'
      langs_to_remove: ['Japanese', 'Korean']
  - punctuation_normalization_mapper:
  - whitespace_normalization_mapper:
#   - chinese_convert_mapper:
    #   mode: t2s

  - alphanumeric_filter: # 104636381
      tokenization: false
      min_ratio: 0.4             # change from 0.1
  - average_line_length_filter:          # filter text with the average length of lines out of specific range.
      min_len: 10                        # the min length of filter range
      max_len: 10000  
  - character_repetition_filter: # 104630030
      rep_len: 10
      max_ratio: 0.6
  - flagged_words_filter: # 104576967
      lang: en
      tokenization: false
      max_ratio: 0.015              # change from 0.01
  - maximum_line_length_filter: # 104575811
      min_len: 20
      max_len: 20000
  - text_length_filter: # 104573711
      min_len: 30
  - output_text_length_filter:
      text_key: 'output'
      min_len: 10
  - perplexity_filter:                                      # filter text with perplexity score out of specific range
      lang: en                                                # compute perplexity in what language
      max_ppl: 1000
  - language_id_score_filter:                               # filter text in specific language with language scores larger than a specific max value
      lang: en                                                # keep text in what language
      min_score: 0.8
#   - specified_field_lang_id_score_filter:
#       lang: en
#       text_key: 'instruction'
#       min_score: 0.8
  - words_num_filter:                                       # filter text with number of words out of specific range
      lang: en                                                # sample in which language
      tokenization: false                                     # whether to use model to tokenize documents
      min_num: 300                                             # the min number of filter range
  - error_filter:
      errors: [
        'network error', 'Network error',
        'There was an error generating a response'
        ]
  - error_filter:
      text_key: 'instruction'
      errors: [
        'continue'
        ]
  - token_num_filter:                                       # filter text with total token number out of specific range
      hf_tokenizer: data/models/falcon-rw-1b            # name of used Hugging Face tokenizer                                        # the min number of filter range
      max_num: 1024                                          # the max number of filter range

  - document_simhash_deduplicator:  # 72855345
      tokenization: space
      window_size: 3
      lowercase: true
      ignore_pattern: '\p{P}'
      num_blocks: 9
      hamming_distance: 7

  - text_len_selector:
      text_key: "text"
      field_keys: "__dj__stats__.text_len"
      min_range: 2000
      max_range: 20000
      interval: 1000
      num_sample: 80000
