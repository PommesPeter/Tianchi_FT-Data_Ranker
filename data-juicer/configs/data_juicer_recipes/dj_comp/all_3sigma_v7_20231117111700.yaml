# global parameters
project_name: 'Data-Juicer-recipes-alpaca-cot-en'
dataset_path: '../data/raw_data/raw_data_en.jsonl'  # path to your dataset directory or file
export_path: ''
ds_cache_dir: '~/data1/huggingface/datasets'

np: 50  # number of subprocess to process your dataset
open_tracer: true
trace_num: 100

# process schedule
# a list of several process operators with their arguments
process:

  - document_deduplicator: # 104636705
      lowercase: true 
      ignore_non_character: true

  - clean_links_mapper:
  - fix_unicode_mapper:
  - keyword_mapper:
      keywords: ['지금 번역하기', '﻿']
  - remove_specific_languages_mapper:
      text_key: 'text'
      langs_to_remove: 'Japanese'
  - remove_specific_languages_mapper:
      text_key: 'text'
      langs_to_remove: 'Korean'
  - punctuation_normalization_mapper:
  - whitespace_normalization_mapper:
#   - chinese_convert_mapper:
    #   mode: t2s

  - alphanumeric_filter: # 104636381
      tokenization: false
      min_ratio: 0.4             # change from 0.1
  - average_line_length_filter:          # filter text with the average length of lines out of specific range.
      min_len: 10                        # the min length of filter range
      max_len: 10000  
  - character_repetition_filter: # 104630030
      rep_len: 10
      max_ratio: 0.6
  - flagged_words_filter: # 104576967
      lang: en
      tokenization: false
      max_ratio: 0.015              # change from 0.01
  - maximum_line_length_filter: # 104575811
      min_len: 20
      max_len: 20000
  - text_length_filter: # 104573711
      min_len: 30
  - output_text_length_filter:
      text_key: 'output'
      min_len: 10
  - perplexity_filter:                                      # filter text with perplexity score out of specific range
      lang: en                                                # compute perplexity in what language
      max_ppl: 1000
  - language_id_score_filter:                               # filter text in specific language with language scores larger than a specific max value
      lang: en                                                # keep text in what language
      min_score: 0.7
  - words_num_filter:                                       # filter text with number of words out of specific range
      lang: en                                                # sample in which language
      tokenization: false                                     # whether to use model to tokenize documents
      min_num: 300                                             # the min number of filter range
  - specified_field_words_num_filter:
      text_key: 'instruction'
      min_num: 3
  - specified_field_words_num_filter:
      text_key: 'output'
      min_num: 5
  - error_filter:
      errors: [
        'network error', 'Network error',
        'There was an error generating a response'
        ]
  - token_num_filter:                                       # filter text with total token number out of specific range
      hf_tokenizer: data/models/falcon-rw-1b            # name of used Hugging Face tokenizer                                        # the min number of filter range
      max_num: 1024                                          # the max number of filter range
  - word_repetition_filter:                                 # filter text with the word repetition ratio out of specific range
      lang: en                                                # sample in which language
      tokenization: false                                     # whether to use model to tokenize documents
      rep_len: 10                                             # repetition length for word-level n-gram
      min_ratio: 0.0                                          # the min ratio of filter range
      max_ratio: 0.93                                          # the max ratio of filter range

  - document_simhash_deduplicator:  # 72855345
      tokenization: space
      window_size: 3
      lowercase: true
      ignore_pattern: '\p{P}'
      num_blocks: 9
      hamming_distance: 7

  - text_len_selector:
      text_key: "text"
      field_keys: "__dj__stats__.text_len"
      min_range: 2000
      max_range: 20000
      interval: 1000
      num_sample: 80000
